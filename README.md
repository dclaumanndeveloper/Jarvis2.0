# ğŸ¤– Jarvis 2.0

Assistente virtual pessoal avanÃ§ado 100% offline desenvolvido em Python, inspirado no J.A.R.V.I.S. do universo Marvel. Possui uma interface grÃ¡fica futurista via HUD interativo, reconhecimento de voz contÃ­nuo e processamento descentralizado e inteligente via IA Local.

![Interface Jarvis 2.0](web/assets/hud_preview.png) *(Exemplo do painel de mÃ©tricas e status)*

---

## âœ¨ Principais Funcionalidades

| Funcionalidade | DescriÃ§Ã£o |
|----------------|-----------|
| ğŸ¤ **Reconhecimento de Voz Offline** | TranscriÃ§Ã£o ultra-rÃ¡pida usando modelos Whisper e detecÃ§Ã£o de wake word via Silero VAD. |
| ğŸ§  **IA Neural Local** | Processamento de comandos complexos e contexto operando 100% offline via **Ollama** (Modelo otimizado: `qwen2:1.5b`). |
| ğŸ–¥ï¸ **Interface HUD AssÃ­ncrona** | Janela translÃºcida, sem bordas, com design futurista operando sobre o PyQt6 e WebEngine. |
| ğŸ”Š **Text-to-Speech Fluido** | SÃ­ntese de voz em portuguÃªs estruturada em Threads assÃ­ncronas (Thread-safe) para evitar bloqueios de UI. |
| âš¡ **Action Controller Modular** | ExecuÃ§Ã£o rÃ¡pida de comandos usando um sistema de rotas (Registry) e intenÃ§Ãµes (`IntentType`). |
| ğŸµ **Controles e AutomaÃ§Ã£o** | AutomaÃ§Ã£o de mÃ­dia corporativa, navegaÃ§Ã£o web, sistema de arquivos e comandos nativos de OS (Windows otimizado). |

---

## ğŸ—ï¸ Arquitetura do Sistema

O sistema difere de assistentes tradicionais por rodar serviÃ§os pesados localmente sem onerar a interface de usuÃ¡rio.

```text
Jarvis2.0/
â”œâ”€â”€ main.py                      # Ponto de entrada; Inicializa UI HUD e delega as Threads.
â”œâ”€â”€ web/                         # Front-end da interface (HTML/CSS/JS renderizado via QtWebEngine).
â”œâ”€â”€ comandos.py                  # Registry de automaÃ§Ãµes (Abrir sites, mÃ­dia, informaÃ§Ãµes do sistema).
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ai_service.py            # Orquestrador da IA Local; gerencia MemÃ³ria e Aprendizado de mÃ¡quina.
â”‚   â”œâ”€â”€ tts_service.py           # Gestor da Fila Falada de respostas.
â”‚   â”œâ”€â”€ voice_processor_v2.py    # Pipeline acÃºstico avanÃ§ado usando processamento nativo VAD.
â”‚   â”œâ”€â”€ optimized_voice_service.py # Lida com Listening-state assÃ­ncrono.
â”‚   â””â”€â”€ action_controller.py     # Disparador final: Resolve IntenÃ§Ãµes para chamadas de sistema (Callables).
â”œâ”€â”€ nlp_processor.py             # Formata Prompts e comunica com Ollama/LocalAI API em formato JSON.
â”œâ”€â”€ conversation_manager.py      # MantÃ©m janela de histÃ³ria contextual do usuÃ¡rio e os Enum Types.
â””â”€â”€ ...
```

---

## ğŸ™ï¸ Exemplos de Comandos (Em PortuguÃªs)

O `AIService` classifica as requisiÃ§Ãµes em IntenÃ§Ãµes para disparo rÃ¡pido ou passa pela IA Local para processamento semÃ¢ntico complexo.

### UtilitÃ¡rios e Sistema
```text
"Jarvis, que horas sÃ£o?"               â†’ `TIME_QUERY` (Responde instantaneamente)
"Qual a data de hoje?"                 â†’ `DATE_QUERY` (Responde sem chamar modelo LLM pesado)
"Bloquear a tela."                     â†’ Trava a sessÃ£o do Windows
"Uso de memÃ³ria / EspaÃ§o em disco."    â†’ ObtÃ©m mÃ©tricas via `psutil`
```

### AutomaÃ§Ã£o (Zero-Shot & Registrados)
```text
"Abrir [Google Chrome / VSCode]."      â†’ Dispara executÃ¡veis de sistema ou injeta busca via GUI.
"Fechar [Aplicativo]."                 â†’ Encerra processos no Task Manager silenciosamente.
"Tocar [Nome da MÃºsica]."              â†’ Abre o vÃ­deo no YouTube automaticamente.
"Criar timer de 5 minutos."             â†’ Agenda processos background usando Regex e Threads.
"Pesquisar sobre buracos negros."      â†’ Encaminha buscas estruturadas web.
```

### InteligÃªncia Contextual (`CONVERSATIONAL_QUERY`)
Qualquer pergunta complexa Ã© redirecionada silenciosamente para o LLM. A API local retorna uma rota semÃ¢ntica do que fazer ou o que dizer de volta ao usuÃ¡rio.

---

## ğŸ“‹ PrÃ©-requisitos e Setup

### 1. Requisitos de Sistema
- **Sistema Operacional:** Recomendado Windows 10/11 (Devido aos bindings de Audio/PyCAW otimizados).
- **Processador local AI:** Placa de vÃ­deo adequada ou CPU com boas threads (Recomendado OpenVINO support).
- **Python:** 3.10+
- **Motor Offline (Ollama):** O Ollama deve estar instalado globalmente e rodando o `qwen2:1.5b`.

### 2. Preparando a IA
Baixe o [Ollama](https://ollama.com/) e, no terminal de sua mÃ¡quina, rode:
```bash
ollama run qwen2:1.5b
```

### 3. InstalaÃ§Ã£o do Projeto
Clone e instale dependÃªncias via Virtual Environment (recomendado):
```bash
git clone https://github.com/dclaumanndeveloper/Jarvis2.0.git
cd Jarvis2.0
python -m venv .venv
.venv\Scripts\activate  # No macOS/Linux use: source .venv/bin/activate
pip install -r requirements.txt
```

### 4. VariavÃ©is de Ambiente (.env)
Se for utilizar provedores em nuvem (Fallback fallback), configure seu `.env`. Caso contrÃ¡rio, o sistema focarÃ¡ na porta local `11434` (Ollama).
```env
LOCAL_MODEL_NAME=qwen2:1.5b
# GEMINI_API_KEY=sua_chave (legado, opcional)
```

### 5. ExecuÃ§Ã£o
Execute com o interpretador nativo da venv (nÃ£o utilize terminais bloqueantes):
```bash
python main.py
```

---

## âš ï¸ Known Issues e Troubleshooting

- **Crash 0xc0000005 (Access Violation):** O projeto forÃ§ou o *import bypass* na `main.py` para injetar pacotes C++ da GPU `openvino_genai` antes das bibliotecas nativas do `PyQt6` para evitar colisÃ£o de alocadores de DLL no Windows.
- **Portas e Microfone:** O script necessita usar a porta padrÃ£o de gravaÃ§Ã£o `44100Hz`, libere permissÃµes nas ConfiguraÃ§Ãµes de Privacidade do microfone.
- **Performance TTS:** Para prevenir loops de feedback (eco), a gravaÃ§Ã£o entra automaticamente em estado *Paused* assÃ­ncrono via conexÃ£o de sinais Qt quando o serviÃ§o `TTS` entra na fila de fala.

---

## ğŸ¤ Contribuindo

Ideias empolgantes ou correÃ§Ãµes? Abra um Pull Request! Modifique ou adicione comandos criando funÃ§Ãµes em `comandos.py` e marcando-as com:
```python
@registry.register(intents=[IntentType.DIRECT_COMMAND], category=CommandCategory.UTILITY)
def seu_comando():
    return "Resposta falada."
```

## ğŸ“„ LicenÃ§a
LicenÃ§a MIT. Livre para uso pessoal, inspirar devkits neurais locais privados, mas modifique os reposiÃ³rios de origem se realizar um fork produtivo.

<p align="center">
  <b>â­ Desenvolvido por <a href="https://github.com/dclaumanndeveloper">dclaumanndeveloper</a></b>
</p>
